rows1 = int(input("Enter the number of rows for the first matrix: "))
cols1 = int(input("Enter the number of columns for the first matrix: "))
rows2 = int(input("Enter the number of rows for the second matrix: "))
cols2 = int(input("Enter the number of columns for the second matrix: "))

if cols1 != rows2:
    print("Matrix multiplication is not possible.")
else:
    matrix1 = []
    matrix2 = []
    result = [[0] * cols2 for _ in range(rows1)]

    print("Enter the elements of the first matrix:")
    for i in range(rows1):
        row = []
        for j in range(cols1):
            value = float(input(f"Enter element [{i+1}][{j+1}]: "))
            row.append(value)
        matrix1.append(row)

    print("Enter the elements of the second matrix:")
    for i in range(rows2):
        row = []
        for j in range(cols2):
            value = float(input(f"Enter element [{i+1}][{j+1}]: "))
            row.append(value)
        matrix2.append(row)

    # Perform matrix multiplication
    for i in range(rows1):
        for j in range(cols2):
            for k in range(cols1):
                result[i][j] += matrix1[i][k] * matrix2[k][j]

    print("Resultant matrix after multiplication:")
    for row in result:
        print(row)
